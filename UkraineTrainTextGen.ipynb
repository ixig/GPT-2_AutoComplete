{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UkraineTrainTextGen.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67219603843f407488cca1ab74f97c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4aa332a51f9047e4a49f4401dfb9b249",
              "IPY_MODEL_7486404c561149ae8426257b9ada67ff",
              "IPY_MODEL_da43bf59195a40aea89db68da14a607a"
            ],
            "layout": "IPY_MODEL_b791afef5c1d41d99e5d7adf57a30573"
          }
        },
        "4aa332a51f9047e4a49f4401dfb9b249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e09532c5aaad4946ac33932c869f37b2",
            "placeholder": "​",
            "style": "IPY_MODEL_fc498b3f45a04a9ab05d7c809e8d84a2",
            "value": "100%"
          }
        },
        "7486404c561149ae8426257b9ada67ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf56d759ce264fcca260c82df39eaaf0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19358e334c014c7f9727e51a8c1eda79",
            "value": 1
          }
        },
        "da43bf59195a40aea89db68da14a607a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf04fc0d70c240029b91935ad33d49a3",
            "placeholder": "​",
            "style": "IPY_MODEL_9ac28eecc80e4e6392254896ee983a83",
            "value": " 1/1 [00:00&lt;00:00,  1.92ba/s]"
          }
        },
        "b791afef5c1d41d99e5d7adf57a30573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09532c5aaad4946ac33932c869f37b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc498b3f45a04a9ab05d7c809e8d84a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf56d759ce264fcca260c82df39eaaf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19358e334c014c7f9727e51a8c1eda79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf04fc0d70c240029b91935ad33d49a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac28eecc80e4e6392254896ee983a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning and Evaluation of DistilGPT2 Language Model"
      ],
      "metadata": {
        "id": "XHAEYgSdTo1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "AckSV_nSpnzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers datasets"
      ],
      "metadata": {
        "id": "R-3IDAaUBUvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments, set_seed\n",
        "import torch\n",
        "import re\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "L_HA5yoSBetO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = './combine.txt'\n",
        "with open(text_file) as f:\n",
        "    text = f.read()\n",
        "my_dict = {\"text\": [text]}\n",
        "dataset = Dataset.from_dict(my_dict)\n",
        "dataset"
      ],
      "metadata": {
        "id": "leIUeJe7BmFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdafc6f7-39a8-4e80-be40-1d9caf59c011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 1\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"distilgpt2\"\n",
        "context_length = 128\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "config = AutoConfig.from_pretrained(checkpoint, n_ctx=context_length, pad_token_id=tokenizer.eos_token_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint, config=config)"
      ],
      "metadata": {
        "id": "CE1hWGKVBqbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(element):\n",
        "    outputs = tokenizer(\n",
        "        element[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=context_length,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_length=True,\n",
        "    )\n",
        "    input_batch = []\n",
        "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
        "        if length == context_length:\n",
        "            input_batch.append(input_ids)\n",
        "    return {\"input_ids\": input_batch}\n",
        "\n",
        "\n",
        "dataset = dataset.map(\n",
        "    tokenize, batched=True, remove_columns=dataset.column_names\n",
        ")\n",
        "dataset"
      ],
      "metadata": {
        "id": "1UVmLk8tByfu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "67219603843f407488cca1ab74f97c0b",
            "4aa332a51f9047e4a49f4401dfb9b249",
            "7486404c561149ae8426257b9ada67ff",
            "da43bf59195a40aea89db68da14a607a",
            "b791afef5c1d41d99e5d7adf57a30573",
            "e09532c5aaad4946ac33932c869f37b2",
            "fc498b3f45a04a9ab05d7c809e8d84a2",
            "bf56d759ce264fcca260c82df39eaaf0",
            "19358e334c014c7f9727e51a8c1eda79",
            "cf04fc0d70c240029b91935ad33d49a3",
            "9ac28eecc80e4e6392254896ee983a83"
          ]
        },
        "outputId": "757a7472-6595-40df-f9a0-51caae606f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67219603843f407488cca1ab74f97c0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids'],\n",
              "    num_rows: 841\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "qFCFuXadB2yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = f\"{checkpoint}-mlm\", per_device_train_batch_size=32,\n",
        "    learning_rate=1e-4, lr_scheduler_type=\"cosine\",\n",
        "    logging_strategy=\"epoch\", evaluation_strategy=\"no\", save_strategy=\"no\",\n",
        "    num_train_epochs=50, log_level=\"error\", report_to=\"none\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model, tokenizer=tokenizer, data_collator=data_collator,\n",
        "    args=training_args, train_dataset=dataset)\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "VaaaT324BMUS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8414bfc1-be43-485a-eaec-e0af6677c917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 08:25, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>3.583700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>3.272000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>3.107900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>2.987200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>2.867800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>2.762100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>2.667100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>2.566200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>2.469600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>2.374300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>297</td>\n",
              "      <td>2.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>324</td>\n",
              "      <td>2.187100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>351</td>\n",
              "      <td>2.103400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>378</td>\n",
              "      <td>2.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>405</td>\n",
              "      <td>1.928000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>432</td>\n",
              "      <td>1.840500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>459</td>\n",
              "      <td>1.758000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>486</td>\n",
              "      <td>1.685300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>513</td>\n",
              "      <td>1.606600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>1.544900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>567</td>\n",
              "      <td>1.476400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>594</td>\n",
              "      <td>1.412800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>621</td>\n",
              "      <td>1.356500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>648</td>\n",
              "      <td>1.304900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>1.255400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>1.202700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>729</td>\n",
              "      <td>1.158500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>756</td>\n",
              "      <td>1.122400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>783</td>\n",
              "      <td>1.089000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>1.060200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>1.028300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>864</td>\n",
              "      <td>1.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>891</td>\n",
              "      <td>0.982300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>918</td>\n",
              "      <td>0.953700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>945</td>\n",
              "      <td>0.936000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>972</td>\n",
              "      <td>0.923200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>999</td>\n",
              "      <td>0.904800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1026</td>\n",
              "      <td>0.896500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1053</td>\n",
              "      <td>0.883600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.870300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1107</td>\n",
              "      <td>0.866100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1134</td>\n",
              "      <td>0.855500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1161</td>\n",
              "      <td>0.852800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1188</td>\n",
              "      <td>0.851400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1215</td>\n",
              "      <td>0.845200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1242</td>\n",
              "      <td>0.841200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1269</td>\n",
              "      <td>0.837100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1296</td>\n",
              "      <td>0.838200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1323</td>\n",
              "      <td>0.841700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.839000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Fine-Tuned Text-Generation on Sample Sentence"
      ],
      "metadata": {
        "id": "mh15gRvyT9eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"./distilgpt2-mlm\"\n",
        "context_length = 128\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "config = AutoConfig.from_pretrained(checkpoint, n_ctx=context_length, pad_token_id=tokenizer.eos_token_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint, config=config).to('cuda')"
      ],
      "metadata": {
        "id": "MYrKELfilHWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_output(output, start_tok=0):\n",
        "  for i in range(output.shape[0]):\n",
        "    print(tokenizer.decode(output[i, start_tok:]))"
      ],
      "metadata": {
        "id": "JieKvfTmrnta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"Ukrainian forces carried out counter offensives against Russian positions on Wednesday, seeking to inflict what\"\n",
        "input_ids = tokenizer(txt, return_tensors='pt')['input_ids'].to('cuda')\n",
        "input_ids"
      ],
      "metadata": {
        "id": "S1kHuN_oMyn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "output = model.generate(input_ids, max_new_tokens=1, num_return_sequences=10,\n",
        "                        num_beams=10, return_dict_in_generate=True, output_scores=True, do_sample=False)\n",
        "print(output['sequences_scores'])\n",
        "decode_output(output['sequences'], len(input_ids[0]))"
      ],
      "metadata": {
        "id": "IbgXVER8dMD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "output = model.generate(input_ids, max_new_tokens=1, num_return_sequences=10, num_beams=10, do_sample=False)\n",
        "decode_output(output, len(input_ids[0]))"
      ],
      "metadata": {
        "id": "tYOZMohlyS89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "output = model.generate(input_ids, max_new_tokens=1, num_return_sequences=10, do_sample=True, top_k=100)\n",
        "decode_output(output, len(input_ids[0]))"
      ],
      "metadata": {
        "id": "wa7pKZLtzfb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "output = model.generate(input_ids, max_new_tokens=1, num_return_sequences=10, do_sample=True, top_p=0.95)\n",
        "decode_output(output, len(input_ids[0]))"
      ],
      "metadata": {
        "id": "ut_s8jQLr8t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "output = model.generate(input_ids, max_new_tokens=1, num_return_sequences=10, do_sample=True, temperature=0.5, top_k=0)\n",
        "decode_output(output, len(input_ids[0]))"
      ],
      "metadata": {
        "id": "tOIkcfi6OULg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating Inference Time (important for text-editor)"
      ],
      "metadata": {
        "id": "b_ekZE5XUOWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "%timeit output = model.generate(input_ids, max_new_tokens=1, num_return_sequences=10, num_beams=10, do_sample=False)"
      ],
      "metadata": {
        "id": "avNeAXrNti3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "%timeit output = model.generate(input_ids, max_new_tokens=1, num_return_sequences=10, do_sample=True, top_k=100)"
      ],
      "metadata": {
        "id": "O1LUkh9EsOko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "%timeit output = model.generate(input_ids, max_new_tokens=1, num_return_sequences=10, do_sample=True, top_p=0.95)"
      ],
      "metadata": {
        "id": "egDSBhkXsXlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "%timeit output = model.generate(input_ids, max_new_tokens=3, num_return_sequences=10, do_sample=True, temperature=0.5, top_k=0)"
      ],
      "metadata": {
        "id": "HR55ba0ctbQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tmE_VjxPPBFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Prediction Accuracy on Out-of-Sample Articles"
      ],
      "metadata": {
        "id": "IDfPCBmWUlLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_CKPT = \"./distilgpt2-mlm\"\n",
        "BANNED_TOKENS = [\n",
        "    [12], [438], [532], [784], [851], [960], [1377], [11420],       # dashes\n",
        "    [0], [1], [4], [6], [11], [13], [14], [25], [26],               # ! \" % ' , / . : ;\n",
        "    [338], [357], [366], [526], [553], [705], [720], [737], [828],  # 's ( \" .\" ,\" ' $ ). ),\n",
        "    [1539], [1600], [1911], [2474], [2637], [7874], [14004]]        # ., \", \". !\" .' .- ,''\n",
        "CTX_LEN = 128\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CKPT)\n",
        "config = AutoConfig.from_pretrained(MODEL_CKPT, n_ctx=CTX_LEN, pad_token_id=tokenizer.eos_token_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_CKPT, config=config).to(device)"
      ],
      "metadata": {
        "id": "U71HHTku_iQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_FILE = 'new1.txt'\n",
        "# TEXT_FILE = 'new2.txt'\n",
        "# TEXT_FILE = 'new3.txt'\n",
        "fin = open(TEXT_FILE, 'r')\n",
        "text_in = fin.read()\n",
        "fin.close()"
      ],
      "metadata": {
        "id": "iMEOVAvaATRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Colors:\n",
        "    Endc = \"\\033[0m\"\n",
        "    LightRed = \"\\033[91m\"\n",
        "    LightGreen = \"\\033[92m\"\n",
        "    LightYellow = \"\\033[93m\"\n",
        "    LightBlue = \"\\033[94m\"\n",
        "    LightMagenta = \"\\033[95m\"\n",
        "    LightCyan = \"\\033[96m\"\n",
        "    LightGray = \"\\033[37m\"\n",
        "    White = \"\\033[97m\"\n",
        "\n",
        "LOOKBACK = 28\n",
        "NEW_TOKENS = 1 + 2\n",
        "NUM_PREDS = 10\n",
        "NUM_BEAMS = NUM_PREDS\n",
        "EXTRA_PREDS = 0\n",
        "\n",
        "OUTPUT_MISSES = False\n",
        "\n",
        "pat_mkr = re.compile(r\"(\\^+)\")\n",
        "pat_mkr_end = re.compile(r\"\\^+$\")\n",
        "pat_sep = re.compile(r\"[\\s-]+\")\n",
        "pat_punct = re.compile(r\"[()\\\".,;:!$%@–—-]\")  # DON'T include \"'\"\n",
        "\n",
        "fout = open('_' + os.path.basename(TEXT_FILE), \"w\")\n",
        "# fout = sys.stdout\n",
        "\n",
        "text_in = text_in.replace(\"\\n\", \"^\")    # insert markers for NL ...\n",
        "text_in = pat_mkr.sub(r\"\\1 \", text_in)  # plus space for splitting \n",
        "words = pat_sep.split(text_in)\n",
        "LB_BUF = [\"\"] * (LOOKBACK - 1) + [words[0]]\n",
        "print(LB_BUF[-1], end=\" \", file=fout)\n",
        "# print(LB_BUF[-1], end=\" \", flush=True)\n",
        "\n",
        "top1_hits, top5_hits, top10_hits = 0, 0, 0\n",
        "\n",
        "for word in words[1:]:\n",
        "    mkrs = pat_mkr_end.search(word)  # check for NL markers\n",
        "    if mkrs:\n",
        "        num_mkrs = len(mkrs.group())\n",
        "        word = word[:-num_mkrs]\n",
        "        sep = \"\\n\" * num_mkrs\n",
        "    else:\n",
        "        sep = \" \"\n",
        "\n",
        "    text_sep = \" \".join(LB_BUF)\n",
        "    text_sep = text_sep.replace(\"^\", \"\")\n",
        "    input_ids = tokenizer(text_sep, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
        "\n",
        "    # Generate first/starter token\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=1,\n",
        "        min_length=len(input_ids),\n",
        "        num_return_sequences=NUM_PREDS + EXTRA_PREDS,\n",
        "        num_beams=NUM_BEAMS + EXTRA_PREDS,\n",
        "        do_sample=False,\n",
        "        bad_words_ids=BANNED_TOKENS\n",
        "    )\n",
        "\n",
        "    # Filter out unsuitable starter tokens\n",
        "    next_first = []\n",
        "    for i in range(output.shape[0]):\n",
        "        next_first.append((i, tokenizer.decode(output[i, len(input_ids[0])]).strip()))\n",
        "    # tmp = [(idx, word) for idx, word in next_first if pat_punct.match(word)]\n",
        "    # if tmp: print(tmp[0][1], output[tmp[0][0], len(input_ids[0])])\n",
        "    next_filt = [idx for idx, word in next_first if not pat_punct.match(word)]\n",
        "    output = output[next_filt]  # remove filtered tokens\n",
        "\n",
        "    # Generate subsequent tokens (for multi-token words)\n",
        "    output = model.generate(\n",
        "        output,\n",
        "        max_new_tokens=NEW_TOKENS - 1,\n",
        "        num_return_sequences=1,\n",
        "        num_beams=1,\n",
        "        do_sample=False,\n",
        "    )\n",
        "\n",
        "    # Split off hypenated words and truncate punctuations\n",
        "    next_words = []\n",
        "    for i in range(output.shape[0]):\n",
        "        next_words.append(tokenizer.decode(output[i, len(input_ids[0]) :]).strip())\n",
        "    next_words = [pat_sep.split(word)[0] for word in next_words if word]\n",
        "    next_words = [word.rstrip(\"\\\"'.,;:!$%@–—-\") for word in next_words]\n",
        "    next_words = [word for word in next_words if word]\n",
        "    next_words = next_words[:NUM_PREDS]  # limit to NUM_PREDS if EXTRA_PREDS > 0\n",
        "\n",
        "    # Check for prediction hits\n",
        "    word_nopunct = pat_punct.sub(\"\", word)  # remove beginning/ending punctuations\n",
        "    if word_nopunct in next_words:\n",
        "        idx = next_words.index(word_nopunct)\n",
        "        if idx == 0:\n",
        "            attr = Colors.LightGreen   # Top-1\n",
        "            top1_hits += 1\n",
        "        elif idx < 5:\n",
        "            attr = Colors.LightCyan    # Top-5\n",
        "            top5_hits += 1\n",
        "        else:\n",
        "            attr = Colors.LightYellow  # Top-10\n",
        "            top10_hits += 1\n",
        "        s = f\"{attr}{word}{Colors.Endc}{sep}\"\n",
        "        print(s, end=\"\", file=fout)\n",
        "        # print(s, end=\"\", flush=True)\n",
        "    else:\n",
        "        if OUTPUT_MISSES:\n",
        "            s = f\"{Colors.LightRed}{'|'.join(next_words)}{Colors.Endc}{sep}\"\n",
        "            print(s, end=\"\", file=fout)\n",
        "            print(s, end=\"\", flush=True)\n",
        "        print(word + sep, end=\"\", file=fout)\n",
        "        # print(word + sep, end=\"\", flush=True)\n",
        "    LB_BUF = LB_BUF[1:] + [word]\n",
        "\n",
        "total_hits = top1_hits + top5_hits + top10_hits\n",
        "s = (\n",
        "    f\"\\n{TEXT_FILE}>> LKBACK: {LOOKBACK}, PREDS: {NUM_PREDS}, EXTRA_PREDS: {EXTRA_PREDS}, NEW_TOKS: {NEW_TOKENS}\"\n",
        "    f\" => #HITS: {top1_hits},{top5_hits},{top10_hits} / {len(words)} ({100*total_hits/len(words):.1f})%\"\n",
        ")\n",
        "print(s, file=fout)\n",
        "print(s)\n",
        "\n",
        "fout.close()"
      ],
      "metadata": {
        "id": "RacvMjtH0Iza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6192025e-895e-49aa-dec8-2030d48a8279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "new1.txt>> LKBACK: 28, PREDS: 10, EXTRA_PREDS: 2, NEW_TOKS: 3 => #HITS: 439,343,135 / 1547 (59.3)%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Look-Back Sequence (Token) Length & Early-Stopping"
      ],
      "metadata": {
        "id": "PTR196pbVd4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 'train_loss': 0.839 ###\n",
        "# old1.txt>> LKBACK: 28, PREDS: 10, EXTRA_PREDS: 0, NEW_TOKS: 3 => #HITS: 1019,177,38 / 1374 (89.8)%\n",
        "# new1.txt>> LKBACK: 28, PREDS: 10, EXTRA_PREDS: 0, NEW_TOKS: 3 => #HITS: 439,343,135 / 1547 (59.3)%\n",
        "# new2.txt>> LKBACK: 28, PREDS: 10, EXTRA_PREDS: 0, NEW_TOKS: 3 => #HITS: 235,180,69 / 852 (56.8)%\n",
        "# new3.txt>> LKBACK: 28, PREDS: 10, EXTRA_PREDS: 0, NEW_TOKS: 3 => #HITS: 321,260,106 / 1202 (57.2)%\n",
        "\n",
        "# new1.txt>> LKBACK: 30, PREDS: 10, EXTRA_PREDS: 0, NEW_TOKS: 3 => #HITS: 433,341,142 / 1547 (59.2)%\n",
        "# new1.txt>> LKBACK: 26, PREDS: 10, EXTRA_PREDS: 0, NEW_TOKS: 3 => #HITS: 429,359,130 / 1547 (59.3)%\n",
        "\n",
        "# new1.txt>> LKBACK: 28, PREDS: 10, EXTRA_PREDS: 2, NEW_TOKS: 3 => #HITS: 439,343,135 / 1547 (59.3)%"
      ],
      "metadata": {
        "id": "1_yi3mOqnssT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 'train_loss': 0.072 ###\n",
        "# new1.txt>> LKBACK: 28, PREDS: 10, EXTRA_PREDS: 0, NEW_TOKS: 3 => #HITS: 411,348,128 / 1547 (57.3)%\n",
        "# new2.txt>> LKBACK: 28, PREDS: 10, EXTRA_PREDS: 0, NEW_TOKS: 3 => #HITS: 222,172,73 / 852 (54.8)%\n",
        "# new3.txt>> LKBACK: 28, PREDS: 10, EXTRA_PREDS: 0, NEW_TOKS: 3 => #HITS: 314,240,111 / 1202 (55.3)%"
      ],
      "metadata": {
        "id": "5otc0ok_YdRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 'train_loss': 0.043 ###\n",
        "# new1.txt>> LKBACK: 28, PREDS: 10, EXTRA_PREDS: 0, NEW_TOKS: 3 => #HITS: 406,334,138 / 1547 (56.8)%\n",
        "# new2.txt>> LKBACK: 28, PREDS: 10, EXTRA_PREDS: 0, NEW_TOKS: 3 => #HITS: 210,177,68 / 852 (53.4)%\n",
        "# new3.txt>> LKBACK: 28, PREDS: 10, EXTRA_PREDS: 0, NEW_TOKS: 3 => #HITS: 319,223,100 / 1202 (53.4)%"
      ],
      "metadata": {
        "id": "g6ZgWQNLkve5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XCnquOhpMFsP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}